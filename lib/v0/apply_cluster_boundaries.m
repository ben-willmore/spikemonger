function data = apply_cluster_boundaries(data, cluster_boundaries)
  % data = apply_cluster_boundaries(data, cluster_boundaries)
  %
  % Function used for importing a previously-exported set of cluster
  % boundaries to a data set. 
  %
  % N.B. this is almost a direct copy of cluster_cut
  
  % In later versions, it is recommended that cluster_boundaries are first
  % generated by EM, then applied; these two stages should be separated,
  % and then several functions can be simplified.
  
  % ======================
  % SPIKEMONGER v1.0.0.19
  % ======================
  %   - NCR 04-Jul-2009
  %   - distributed under GPL v3 (see COPYING)


%% initialise
% =============

warning off MATLAB:singularMatrix
warning off MATLAB:nearlySingularMatrix

% get features
  features = extract_features(data);
  features_to_use = cluster_boundaries.features;  
  n.clusters = L(cluster_boundaries.W);
  stdmax = cluster_boundaries.stdmax;

% parse features
  X = [];
  for ii=1:L(features_to_use)
    X = [X; features.(features_to_use{ii})];
  end
  X = X';
      
  
%% post-EM
% ===========

  W = cluster_boundaries.W;
  M = cluster_boundaries.M;
  V = cluster_boundaries.V;

  % fix covariances if necessary
    for ii=1:n.clusters
      for jj=1:size(X,2)
        if V(jj,jj,ii) == 0
          V(jj,jj,ii) = eps;
        end
      end
    end
      
      
  [C P best_P NStds best_NStds]  = EM_classify( X, W, M, V );
  C(best_NStds>stdmax) = n.clusters+1; 
  C = C';
  loglik = sum(log(sum(P,2)));
  
%% subdivide data into clusters
% ================================

  fields    = fieldnames(data.spikes);
  n.fields  = L(fields);
  
  for ii=1:(n.clusters+1)
    for jj=1:n.fields
      field = pick(fields,jj,'c');
      cluster(ii).spikes.(field) = data.spikes.(field)(:,C==ii);
    end
    %cluster(ii).sweeps  = spikes_to_sweeps(cluster(ii).spikes);
    cluster(ii).nspikes = L(cluster(ii).spikes.t_absolute_dt);
  end
  
%% calculate some statistics
% ===========================

% psth
  for cc=1:(n.clusters+1)
    %tt = 0 : 5 : (floor(data.metadata.maxt_ms*5)/5);
    %cluster(cc).psth.tt     = tt(1:(end-1))+2.5;
    tt = linspace(0, data.metadata.maxt_ms, 100);
    cluster(cc).psth.tt     = tt(1:(end-1)) + (tt(2)-tt(1))/2;
    cluster(cc).psth.count  = histc(cluster(cc).spikes.t_insweep_ms,tt);    
    cluster(cc).psth.count  = cluster(cc).psth.count(1:(end-1));    
  end
  
% autocorrelogram & ISI
  for cc=1:(n.clusters+1)
    if cluster(cc).nspikes == 0
      cluster(cc).autocorrelogram.tt          = [];
      cluster(cc).autocorrelogram.count       = [];
      cluster(cc).interspike_interval.tt      = [];
      cluster(cc).interspike_interval.count   = [];
    else
      [tt acg isi] = get_autocorrelogram(cluster(cc).spikes,0.5);
      cluster(cc).autocorrelogram.tt    = tt;
      cluster(cc).autocorrelogram.count = acg;
      cluster(cc).interspike_interval.tt    = tt;
      cluster(cc).interspike_interval.count = isi;
    end
  end
  
% spike counts over repeat number
  n.repeats = data.metadata.n.repeats;  
  for cc = 1:(n.clusters+1)
    repeatcounts = nan * zeros( 1, n.repeats );
      for ii = 1:n.repeats
        repeatcounts(ii) = sum(cluster(cc).spikes.repeat_id == ii);
      end
    cluster(cc).spikes_per_repeat.repeat_id  = 1:n.repeats;
    cluster(cc).spikes_per_repeat.count      = repeatcounts;
  end  

  
%% prepare output structure
% ===========================

data.cluster = cluster;
data.nspikes = [data.cluster.nspikes];

data.EM = struct;
  data.EM.features = features_to_use;
  data.EM.X = X;
  data.EM.W = W;
  data.EM.M = M;
  data.EM.V = V;
  data.EM.C = C;
  data.EM.P = P;
  data.EM.best_P = best_P;
  data.EM.NStds = NStds;
  data.EM.best_NStds = best_NStds;
  data.EM.stdmax = stdmax;
  data.EM.log_likelihood = loglik;
  
  
end



